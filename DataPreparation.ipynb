{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Creating training data ...\n",
      "INFO:root:Processed training images count: 576\n",
      "INFO:root:Creating training data DONE\n",
      "INFO:root:Creating testing data ...\n",
      "INFO:root:Processed testing images count: 384\n",
      "INFO:root:Creating testing data DONE\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"\n",
    "Prepare the data for processing.\n",
    "\"\"\"\n",
    "import logging\n",
    "\n",
    "import math\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "#Configuration/parameters\n",
    "classes_count = 11\n",
    "image_width = (2*176)//1\n",
    "image_height = 128//1\n",
    "image_data_size = image_width*image_height\n",
    "channels = 1\n",
    "\n",
    "data_root_path = \"./\"\n",
    "\n",
    "input_data_file_path = data_root_path + 'data-release.zip'\n",
    "\n",
    "training_image_data_file_path = data_root_path + 'image_train.data'\n",
    "training_labels_data_file_path = data_root_path + 'image_train_labels.csv'\n",
    "testing_data_file_path = data_root_path + 'image_test.data'\n",
    "\n",
    "testing_submission_file_path = data_root_path + 'submission_format.csv'\n",
    "\n",
    "def compose_train_image(p_img1, p_img2) :\n",
    "    \"\"\"\n",
    "    Creates a horizontally stacked image using two input images\n",
    "    @params:\n",
    "        p_img1 - Required : first image source (Image)\n",
    "        p_img2 - Required : second image source (Image) \n",
    "    @returns:\n",
    "        The stacked image (Image)    \n",
    "    \"\"\" \n",
    "\n",
    "    #Stacks images horizontally (i.e. one afer another on width axis)\n",
    "    img_merge_data = np.hstack([np.asarray(p_img1), np.asarray(p_img2)])\n",
    "    img_merge = Image.fromarray( img_merge_data )\n",
    "        \n",
    "    return img_merge\n",
    "\n",
    "def get_image_data(p_image) :\n",
    "    \"\"\"\n",
    "    Returns a flatten array of image pixel values (1 channel gray pallete)\n",
    "    @params:\n",
    "        p_image - Required : the input image (Image)\n",
    "    @returns:\n",
    "        Flattened array of image data (array)\n",
    "    \"\"\"  \n",
    "\n",
    "    #Generates image data from the received image object\n",
    "    width, height = p_image.size\n",
    "    data = np.asarray(p_image).reshape(height*width)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_trainining_images_data_file(p_input_data_file_path, p_training_data_file_path):\n",
    "    \"\"\"\n",
    "    Creates training information data\n",
    "    @params:\n",
    "        p_input_data_file_path - Required: the input data file path (String)\n",
    "        p_training_data_file_path - Required: the output training data file path (String)\n",
    "    @returns:\n",
    "        The extracted training labels (array)\n",
    "    \"\"\"  \n",
    "\n",
    "    training_labels_file_path = 'train_labels.csv'\n",
    "    \n",
    "    labels = None\n",
    "\n",
    "    with open(p_training_data_file_path, 'w+b') as data_file :\n",
    "        with ZipFile(p_input_data_file_path) as data_zip:\n",
    "            with data_zip.open(training_labels_file_path) as train_labels_file:\n",
    "                content = train_labels_file.read()\n",
    "                with BytesIO(content) as io_content:\n",
    "                    train_labels = pd.read_csv(io_content)\n",
    "\n",
    "                    max_count = train_labels.shape[0]    \n",
    "                    labels = np.zeros(max_count)\n",
    "\n",
    "                    count = 0\n",
    "\n",
    "                    for _, row in train_labels.iterrows() :\n",
    "\n",
    "                        with data_zip.open('train/' + str(row[\"id\"]) + \"_c.png\") as c_file :\n",
    "                            with BytesIO(c_file.read()) as input_buffer:\n",
    "                                c_image = Image.open(input_buffer).convert(\"L\")\n",
    "\n",
    "                        with data_zip.open('train/' + str(row[\"id\"]) + \"_v.png\") as v_file :\n",
    "                            with BytesIO(v_file.read()) as input_buffer:\n",
    "                                v_image = Image.open(input_buffer).convert(\"L\")\n",
    "\n",
    "                        image_data = get_image_data(compose_train_image(c_image, v_image))\n",
    "\n",
    "                        labels[count] = row[\"appliance\"]\n",
    "                        data_file.write(image_data)\n",
    "\n",
    "                        count = count + 1       \n",
    "\n",
    "    return labels[:count]\n",
    "\n",
    "def create_training_labels(p_labels, p_labels_data_file_path) :\n",
    "    \"\"\"\n",
    "    Writes the training labels to a destination file\n",
    "    @params:\n",
    "        p_labels - Required: the array of labels (array)\n",
    "    \"\"\" \n",
    "\n",
    "    classes = pd.DataFrame(p_labels.astype(int))\n",
    "    classes.to_csv(p_labels_data_file_path, header=None)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def create_testing_images_data_file(p_input_data_file_path, p_testing_data_file_path):\n",
    "    \"\"\"\n",
    "    Creates testing information data\n",
    "    @params:\n",
    "        p_input_data_file_path - Required: the input data file path (String)\n",
    "        p_testing_data_file_path - Required: the output testing data file path (String)\n",
    "    @returns:\n",
    "        The count of test images (int)\n",
    "    \"\"\"  \n",
    "\n",
    "    submission_format_file_path = 'submission_format.csv'\n",
    "\n",
    "    with open(p_testing_data_file_path, 'w+b') as data_file :\n",
    "        with ZipFile(p_input_data_file_path) as data_zip:\n",
    "            with data_zip.open(submission_format_file_path) as submission_format_file:\n",
    "                content = submission_format_file.read()\n",
    "                with BytesIO(content) as io_content:\n",
    "                    submission_indexes = pd.read_csv(io_content)\n",
    "\n",
    "                    count = 0\n",
    "\n",
    "                    for _, row in submission_indexes.iterrows() :\n",
    "\n",
    "                        with data_zip.open('test/' + str(row[\"id\"]) + \"_c.png\") as c_file :\n",
    "                            with BytesIO(c_file.read()) as input_buffer:\n",
    "                                c_image = Image.open(input_buffer).convert(\"L\")\n",
    "\n",
    "                        with data_zip.open('test/' + str(row[\"id\"]) + \"_v.png\") as v_file :\n",
    "                            with BytesIO(v_file.read()) as input_buffer:\n",
    "                                v_image = Image.open(input_buffer).convert(\"L\")\n",
    "\n",
    "                        image_data = get_image_data(compose_train_image(c_image, v_image))\n",
    "                        data_file.write(image_data)\n",
    "\n",
    "                        count = count + 1       \n",
    "\n",
    "    return count\n",
    "\n",
    "def create_testing_submission(p_input_data_file_path, p_testing_submission_file_path) :\n",
    "    \"\"\"\n",
    "    Writes the submission data to a destination file\n",
    "    @params:\n",
    "        p_input_data_file_path - Required: the input data file path (String)\n",
    "        p_testing_submission_file_path - Required: the testing submission file path (String)\n",
    "    \"\"\" \n",
    "    submission_format_file_path = 'submission_format.csv'\n",
    "\n",
    "    with ZipFile(p_input_data_file_path) as data_zip:\n",
    "        with data_zip.open(submission_format_file_path) as submission_format_file:\n",
    "            content = submission_format_file.read()\n",
    "            with BytesIO(content) as io_content:\n",
    "                submission_indexes = pd.read_csv(io_content)\n",
    "                submission_indexes.to_csv(p_testing_submission_file_path, index=False)\n",
    "\n",
    "    return\n",
    "\n",
    "def main() :\n",
    "    \"\"\"\n",
    "    Entry point\n",
    "    \"\"\"\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    \n",
    "    #create training data\n",
    "    logging.info('Creating training data ...')\n",
    "    training_labels  = create_trainining_images_data_file(input_data_file_path, training_image_data_file_path)\n",
    "    create_training_labels(training_labels, training_labels_data_file_path)\n",
    "    logging.info(\"Processed training images count: %d\" % training_labels.shape[0])\n",
    "    logging.info('Creating training data DONE')\n",
    "\n",
    "    logging.info('Creating testing data ...')\n",
    "    testing_count = create_testing_images_data_file(input_data_file_path, testing_data_file_path)\n",
    "    create_testing_submission(input_data_file_path, testing_submission_file_path)\n",
    "    logging.info(\"Processed testing images count: %d\" % testing_count)\n",
    "    logging.info('Creating testing data DONE')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
