{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Creating training data ...\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: './data-release/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-04f7684c7cd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-04f7684c7cd2>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;31m#create training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Creating training data ...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m     \u001b[0mtraining_labels\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mcreate_trainining_images_data_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_image_data_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m     \u001b[0mcreate_training_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_labels_data_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Processed training images count: %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-04f7684c7cd2>\u001b[0m in \u001b[0;36mcreate_trainining_images_data_file\u001b[1;34m(p_input_data_file_path, p_training_data_file_path)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_training_data_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w+b'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdata_file\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_input_data_file_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdata_zip\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mdata_zip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_labels_file_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrain_labels_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_labels_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda\\lib\\zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[0;32m   1205\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1208\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: './data-release/'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"\n",
    "Prepares data for easier processing by the neural net classifier.\n",
    "\"\"\"\n",
    "import logging\n",
    "\n",
    "import math\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "#Configuration/parameters\n",
    "classes_count = 11\n",
    "image_width = (2*118)//1\n",
    "image_height = 128//1\n",
    "image_data_size = image_width*image_height\n",
    "channels = 1\n",
    "\n",
    "data_root_path = './data/'\n",
    "\n",
    "input_data_file_path = data_root_path + 'data-release.zip'\n",
    "\n",
    "training_image_data_file_path = data_root_path + 'image_train.data'\n",
    "training_labels_data_file_path = data_root_path + 'image_train_labels.csv'\n",
    "testing_data_file_path = data_root_path + 'image_test.data'\n",
    "\n",
    "testing_submission_file_path = data_root_path + 'submission_format.csv'\n",
    "\n",
    "def compose_train_image(p_img1, p_img2) :\n",
    "    \"\"\"\n",
    "    Creates a horizontally stacked image using two input images\n",
    "    @params:\n",
    "        p_img1 - Required : first image source (Image)\n",
    "        p_img2 - Required : second image source (Image) \n",
    "    @returns:\n",
    "        The stacked image (Image)    \n",
    "    \"\"\" \n",
    "\n",
    "    #Stacks images horizontally (i.e. one afer another on width axis)\n",
    "    img_merge_data = np.hstack([np.asarray(p_img1), np.asarray(p_img2)])\n",
    "    img_merge = Image.fromarray( img_merge_data )\n",
    "        \n",
    "    return img_merge\n",
    "\n",
    "def get_image_data(p_image) :\n",
    "    \"\"\"\n",
    "    Returns a flatten array of image pixel values (1 channel gray pallete)\n",
    "    @params:\n",
    "        p_image - Required : the input image (Image)\n",
    "    @returns:\n",
    "        Flattened array of image data (array)\n",
    "    \"\"\"  \n",
    "\n",
    "    #Generates image data from the received image object\n",
    "    width, height = p_image.size\n",
    "    data = np.asarray(p_image).reshape(height*width)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_trainining_images_data_file(p_input_data_file_path, p_training_data_file_path):\n",
    "    \"\"\"\n",
    "    Creates training information data\n",
    "    @params:\n",
    "        p_input_data_file_path - Required: the input data file path (String)\n",
    "        p_training_data_file_path - Required: the output training data file path (String)\n",
    "    @returns:\n",
    "        The extracted training labels (array)\n",
    "    \"\"\"  \n",
    "\n",
    "    training_labels_file_path = 'train_labels.csv'\n",
    "    \n",
    "    labels = None\n",
    "\n",
    "    with open(p_training_data_file_path, 'w+b') as data_file :\n",
    "        with ZipFile(p_input_data_file_path) as data_zip:\n",
    "            with data_zip.open(training_labels_file_path) as train_labels_file:\n",
    "                content = train_labels_file.read()\n",
    "                with BytesIO(content) as io_content:\n",
    "                    train_labels = pd.read_csv(io_content)\n",
    "\n",
    "                    max_count = train_labels.shape[0]    \n",
    "                    labels = np.zeros(max_count)\n",
    "\n",
    "                    count = 0\n",
    "\n",
    "                    for _, row in train_labels.iterrows() :\n",
    "\n",
    "                        with data_zip.open('train/' + str(row[\"id\"]) + \"_c.png\") as c_file :\n",
    "                            with BytesIO(c_file.read()) as input_buffer:\n",
    "                                c_image = Image.open(input_buffer).convert(\"L\")\n",
    "\n",
    "                        with data_zip.open('train/' + str(row[\"id\"]) + \"_v.png\") as v_file :\n",
    "                            with BytesIO(v_file.read()) as input_buffer:\n",
    "                                v_image = Image.open(input_buffer).convert(\"L\")\n",
    "\n",
    "                        image_data = get_image_data(compose_train_image(c_image, v_image))\n",
    "\n",
    "                        labels[count] = row[\"appliance\"]\n",
    "                        data_file.write(image_data)\n",
    "\n",
    "                        count = count + 1       \n",
    "\n",
    "    return labels[:count]\n",
    "\n",
    "def create_training_labels(p_labels, p_labels_data_file_path) :\n",
    "    \"\"\"\n",
    "    Writes the training labels to a destination file\n",
    "    @params:\n",
    "        p_labels - Required: the array of labels (array)\n",
    "    \"\"\" \n",
    "\n",
    "    classes = pd.DataFrame(p_labels.astype(int))\n",
    "    classes.to_csv(p_labels_data_file_path, header=None)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def create_testing_images_data_file(p_input_data_file_path, p_testing_data_file_path):\n",
    "    \"\"\"\n",
    "    Creates testing information data\n",
    "    @params:\n",
    "        p_input_data_file_path - Required: the input data file path (String)\n",
    "        p_testing_data_file_path - Required: the output testing data file path (String)\n",
    "    @returns:\n",
    "        The count of test images (int)\n",
    "    \"\"\"  \n",
    "\n",
    "    submission_format_file_path = 'submission_format.csv'\n",
    "\n",
    "    with open(p_testing_data_file_path, 'w+b') as data_file :\n",
    "        with ZipFile(p_input_data_file_path) as data_zip:\n",
    "            with data_zip.open(submission_format_file_path) as submission_format_file:\n",
    "                content = submission_format_file.read()\n",
    "                with BytesIO(content) as io_content:\n",
    "                    submission_indexes = pd.read_csv(io_content)\n",
    "\n",
    "                    count = 0\n",
    "\n",
    "                    for _, row in submission_indexes.iterrows() :\n",
    "\n",
    "                        with data_zip.open('test/' + str(row[\"id\"]) + \"_c.png\") as c_file :\n",
    "                            with BytesIO(c_file.read()) as input_buffer:\n",
    "                                c_image = Image.open(input_buffer).convert(\"L\")\n",
    "\n",
    "                        with data_zip.open('test/' + str(row[\"id\"]) + \"_v.png\") as v_file :\n",
    "                            with BytesIO(v_file.read()) as input_buffer:\n",
    "                                v_image = Image.open(input_buffer).convert(\"L\")\n",
    "\n",
    "                        image_data = get_image_data(compose_train_image(c_image, v_image))\n",
    "                        data_file.write(image_data)\n",
    "\n",
    "                        count = count + 1       \n",
    "\n",
    "    return count\n",
    "\n",
    "def create_testing_submission(p_input_data_file_path, p_testing_submission_file_path) :\n",
    "    \"\"\"\n",
    "    Writes the submission data to a destination file\n",
    "    @params:\n",
    "        p_input_data_file_path - Required: the input data file path (String)\n",
    "        p_testing_submission_file_path - Required: the testing submission file path (String)\n",
    "    \"\"\" \n",
    "    submission_format_file_path = 'submission_format.csv'\n",
    "\n",
    "    with ZipFile(p_input_data_file_path) as data_zip:\n",
    "        with data_zip.open(submission_format_file_path) as submission_format_file:\n",
    "            content = submission_format_file.read()\n",
    "            with BytesIO(content) as io_content:\n",
    "                submission_indexes = pd.read_csv(io_content)\n",
    "                submission_indexes.to_csv(p_testing_submission_file_path, index=False)\n",
    "\n",
    "    return\n",
    "\n",
    "def main() :\n",
    "    \"\"\"\n",
    "    Entry point\n",
    "    \"\"\"\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    \n",
    "    #create training data\n",
    "    logging.info('Creating training data ...')\n",
    "    training_labels  = create_trainining_images_data_file(input_data_file_path, training_image_data_file_path)\n",
    "    create_training_labels(training_labels, training_labels_data_file_path)\n",
    "    logging.info(\"Processed training images count: %d\" % training_labels.shape[0])\n",
    "    logging.info('Creating training data DONE')\n",
    "\n",
    "    logging.info('Creating testing data ...')\n",
    "    testing_count = create_testing_images_data_file(input_data_file_path, testing_data_file_path)\n",
    "    create_testing_submission(input_data_file_path, testing_submission_file_path)\n",
    "    logging.info(\"Processed testing images count: %d\" % testing_count)\n",
    "    logging.info('Creating testing data DONE')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
